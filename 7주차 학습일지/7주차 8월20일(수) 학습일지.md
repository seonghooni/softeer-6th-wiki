# 1. 리뷰
## :laughing: 오늘 한 작업
### 🔹 부하테스트에 대한 학습 및 적용

어제 구축한 CloudWatch 모니터링 설정을 바탕으로, k6를 이용해 EC2 서버에 부하를 발생시켜봤다.

내가 측정하고 싶었던 API는 경로 정보를 전달해주는 "동행 상세정보 API"였다.

동행 상세정보에서는 경로를 나타내는 List<Coordinate>를 제공해주는데, 이 List의 크기가 3시간 거리 기준 2000 정도 되었다.

이러한 경로 데이터를 요청하는 API를 지속적으로 호출해보았다.

처음에는 30초간 50개, 그리고 점차 100개, 200, 500개로 늘려가면서 요청을 발생시켜봤다.

Throughput과 Latency를 보니, 예상과는 다르게 응답이 무난하게 잘 왔다.

사실 이 부분에서 병목이 많이 발생할 것이라고 생각하고 개선해나가고자 했는데, 생각보다 괜찮은 수준의 결과가 나와서 적잖이 당황했다.

다시 생각해보니, size 2000이면 그렇게 부담스러운 데이터는 아닐 것 같다는 생각을 했고, 개선의 여지가 매우 많지는 않을 것이라고 생각했다.

고민이 너무 많아져, 오후 2시간동안은 멘토님과 이에 대해 많은 이야기를 나눴던 것 같다.

우리 팀이 다른 팀들과의 차별점이 무엇인가를 고민해봐야 할 것 같다.

<br>


## :dizzy: 작업 과정에서 배운점

### 🔹 예상과 달리, 성능 병목은 발견되지 않았다.

막연히 병목이 될 것이라 생각했던 부분이 실제로는 크게 문제되지 않았다는 사실은, 테스트를 통해서만 확인할 수 있었다. 

단순히 코드와 데이터 크기만 보고 추측하는 것보다, 실제 환경에서 시뮬레이션을 돌려보는 것이 훨씬 명확한 답을 준다.

이를 통해 앞으로는 성능이나 안정성 관련 의사결정을 할 때 "추측"보다 "검증"을 우선시해야 한다는 교훈을 얻었다.


<br>

## :sob: 어려웠던 점

### 🔹 남은 기간 어떤 지점에 몰입을 해볼 수 있을까..

사실상 API 구현은 끝난 이 시점에서, 프론트엔드와 QA를 진행하며 고쳐나가는 작업외에는 개발 작업이 끝난 상태다.

남은 시간을 알차게 사용하기 위해 나와 팀원은 성능을 개선할 지점이 있는지 알아보고자 했고, 명확한 문제를 발견하지 못했다.

정말 오랜 시간 고민하고 상담한 후에,

우리 팀만이 가진 차별 포인트는 바로 '테스트 케이스'인 것 같다.

우리 팀은 개발을 진행하며 테스트코드를 함께 작성하여, 배포 이후 수정사항을 최소화하기로 했고, 대체로 잘 지켜지긴 했다. (마지막 기간에 개발했던 기능은 추가로 작성해야 하긴 하지만 말이다.)

테스트 커버리지가 높다고 해서, 서비스에 버그가 나지 않는다는 말은 아니다.

위험을 줄여주는 것이지, 높은 테스트 커버리지가 곧 신뢰성 높은 서비스를 의미하는 것은 아니다.

테스트 코드를 얼마나 꼼꼼히 작성할 것인지, 또 너무 많은 케이스를 검증하면 개발 시간이 줄어드는 것은 아닌지 여러 방면에서 고민하고 적용해야 한다.

나는 남은 기간동안 우리 서비스에서 적용되지 않은 테스트들..  
성공하는 케이스 외에도 실패하는 케이스들, 경계값 테스트, 동시성 테스트 등 다양한 테스트를 진행하며  
우리 서비스의 기능을 검증해 나가려고 한다.

그리고 이렇게 테스트 케이스가 많아지면, CI/CD 과정에서 발생하는 테스트 실행시간이 길어지기 마련인데.. (실제로 지금도 배포하는데 왜이렇게 테스트에서 오랜 시간을 잡아먹는지 모르겠다.)  
테스트 실행 시간을 최적화하는 방법을 고민해보고 적용해보려고 한다.


<br><br>

# 2. 회고 (KPT)

✅ **K – Keep (유지할 것)**
- 근거 있는 개선을 하자.

🛠️ **P – Problem (개선이 필요한 점)**
- 남은 기간 동안, 테스트라는 주제로 고민을 해보기로 했으니, 이에 관해 더욱 많은 학습이 필요할 것 같다.
  
🔄 **T – Try (시도할 것)**
- 테스트 커버리지를 어떻게 가져가는게 좋을지, 또 문제상황은 무엇이 있을지 예상하고 관련 기술 학습해보기
