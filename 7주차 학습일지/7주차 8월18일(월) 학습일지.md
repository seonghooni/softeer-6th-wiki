# 1. 리뷰
## :laughing: 오늘 한 작업
### 🔹 API 연동하며 문제 대응하기

그동안 단위 테스트(서비스 계층)와 통합 테스트를 작성했기에, API 로직 과정중 오류는 발생하지는 않았다.

다만 API 호출과정에서 mock데이터끼리 일부 일관성이 맞지 않는 문제가 있었고,  

프론트엔드에서 페이지 라우팅 과정에서 누락되거나 자연스러운 흐름을 원하셔서 그에 맞게 API를 수정하는 작업을 진행했다.

오늘은 거의 위 작업에서 대부분의 시간을 보낸 것 같다.

또한, 앞으로 로깅을 위해 Spring AOP를 이용해 적용하였고,

모니터링을 어떤 도구를 사용할지 찾아보았다.

뉴렐릭, 프로메테우스+그라파나, CloudWatch 등 모니터링 도구들을 비교하며 어떤 조합이 우리 환경에 적합할지 탐색했다.

<br>


## :dizzy: 작업 과정에서 배운점

### 🔹 우리 프로젝트에서는 어떤 모니터링 도구를 써야 할까?

뉴렐릭은 손쉽게 전체 애플리케이션 성능을 한눈에 볼 수 있지만 비용 부담이 크다.

프로메테우스+그라파나는 커스터마이징 자유도가 높고 오픈소스 기반이라 비용 효율적이지만, 초기 세팅 및 운영 부담이 있다.  
또한, 우리 t4g.micro 스펙의 EC2 환경에서 컨테이너를 하나 더 띄워야 한다는 문제가 있다.

CloudWatch는 AWS 인프라와 통합성이 뛰어나지만 지표 시각화·확장성 측면에서는 한계가 있다.

결론적으로, 저사양 EC2 환경에서는 CloudWatch Agent를 활용한 모니터링 구성이 더 적합할 수 있다고 판단했다.

<br>

## :sob: 어려웠던 점

### 🔹 부하테스트 시나리오 설계

실제 트래픽과 유사한 부하 시나리오를 어떻게 구성해야 현실적인 결과를 얻을 수 있을지 고민을 했다.
단순히 동시 접속자 수를 늘리는 것만으로는 충분치 않고, 실시간 위치 공유 + API 호출이 복합적으로 발생하는 상황을 재현해야 한다는 점이 도전적이었다.

<br><br>

# 2. 회고 (KPT)

✅ **K – Keep (유지할 것)**
- 백엔드가 일찍 API를 마무리했으니, 프론트엔드의 요청에 최대한 맞춰주며 일정 조절하기


🛠️ **P – Problem (개선이 필요한 점)**
- 프론트엔드측 페이지가 100% 구축되기 전까지 우리가 성능 테스트를 할 수 있는 방안을 탐색해야 한다.
  
🔄 **T – Try (시도할 것)**
- 할당받은 IAM 계정에 CloudWatch Agent를 사용하기 위한 Role이 없어 직접 셋팅하지는 못했다.
  내일은 해당 권한을 요청드리고 직접 셋팅해봐야 할 것 같다.
